{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py38/lib/python3.10/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/anaconda/envs/azureml_py38/lib/python3.10/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/anaconda/envs/azureml_py38/lib/python3.10/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from PIL import Image\n",
    "import subprocess\n",
    "from ultralytics import YOLO, SAM\n",
    "import matplotlib.pyplot as plt\n",
    "import open_clip\n",
    "from transformers import CLIPProcessor, CLIPModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_from_video(video_path, frame_number):\n",
    "    \"\"\"\n",
    "    Captures a specific frame from a video file.\n",
    "\n",
    "    Args:\n",
    "        video_path (str): The path to the MP4 video file.\n",
    "        frame_number (int): The 0-indexed number of the frame to capture.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The image data of the specified frame as a NumPy array (BGR format).\n",
    "                       Returns None if the frame cannot be captured or video cannot be opened.\n",
    "    \"\"\"\n",
    "    # Open the video file\n",
    "    video_capture = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Check if video opened successfully\n",
    "    if not video_capture.isOpened():\n",
    "        print(f\"Error: Could not open video file: {video_path}\")\n",
    "        return None\n",
    "\n",
    "    # Get total number of frames (optional, for validation)\n",
    "    total_frames = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    # print(f\"Total frames in video: {total_frames}\")\n",
    "\n",
    "    if frame_number < 0 or frame_number >= total_frames:\n",
    "        print(f\"Error: Frame number {frame_number} is out of bounds (0-{total_frames - 1}).\")\n",
    "        video_capture.release()\n",
    "        return None\n",
    "\n",
    "    # Set the video capture to the desired frame\n",
    "    # cv2.CAP_PROP_POS_FRAMES is 0-based index of the frame to be decoded/captured next.\n",
    "    video_capture.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "\n",
    "    # Read the frame\n",
    "    success, frame = video_capture.read()\n",
    "\n",
    "    # Release the video capture object\n",
    "    video_capture.release()\n",
    "\n",
    "    if success:\n",
    "        # 'frame' is now a NumPy array containing the image data of the specified frame\n",
    "        return frame\n",
    "    else:\n",
    "        print(f\"Error: Could not read frame {frame_number} from video {video_path}.\")\n",
    "        return None\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     # --- Example Usage ---\n",
    "#     video_file_path = \"path/to/your/video.mp4\"  # Replace with your video file path\n",
    "#     frame_to_capture = 100  # Capture the 101st frame (0-indexed)\n",
    "\n",
    "#     # Get the specific frame\n",
    "#     captured_frame_data = get_frame_from_video(video_file_path, frame_to_capture)\n",
    "\n",
    "#     if captured_frame_data is not None:\n",
    "#         print(f\"Successfully captured frame {frame_to_capture}.\")\n",
    "#         print(f\"Frame data type: {type(captured_frame_data)}\")\n",
    "#         print(f\"Frame shape (Height, Width, Channels): {captured_frame_data.shape}\")\n",
    "#         print(f\"Frame dtype: {captured_frame_data.dtype}\")\n",
    "\n",
    "#         # You can now process or display this frame\n",
    "#         # For example, display it using OpenCV (requires a GUI environment)\n",
    "#         # cv2.imshow(f\"Frame {frame_to_capture}\", captured_frame_data)\n",
    "#         # cv2.waitKey(0)  # Wait for a key press\n",
    "#         # cv2.destroyAllWindows()\n",
    "\n",
    "#         # Or save it to a file\n",
    "#         # cv2.imwrite(f\"captured_frame_{frame_to_capture}.jpg\", captured_frame_data)\n",
    "#         # print(f\"Frame {frame_to_capture} saved as captured_frame_{frame_to_capture}.jpg\")\n",
    "#     else:\n",
    "#         print(f\"Failed to capture frame {frame_to_capture}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_yolo_data_single_class(localization_data, base_dataset_dir, object_class_name=\"object\"):\n",
    "    \"\"\"\n",
    "    Converts structured localization data for a single object class to YOLO format.\n",
    "    Assumes already normalized bounding boxes.\n",
    "\n",
    "    Args:\n",
    "        localization_data: A list of dictionaries, where each dict has:\n",
    "                           'frame_num': int, the frame number for naming.\n",
    "                           'frame': numpy.ndarray, the image data.\n",
    "                           'boxes': a list of dicts, each with normalized 'x', 'y', 'width', 'height'.\n",
    "                                    The 'class_name' field in boxes is ignored as it's a single class.\n",
    "                                    'x', 'y' are top-left corner normalized.\n",
    "                                    'width', 'height' are normalized dimensions.\n",
    "        base_dataset_dir: Path to the root of your YOLO dataset.\n",
    "        object_class_name (str): The name to use for your single class in data.yaml (e.g., \"object\").\n",
    "    \"\"\"\n",
    "    images_train_dir = os.path.join(base_dataset_dir, \"images\", \"train\")\n",
    "    labels_train_dir = os.path.join(base_dataset_dir, \"labels\", \"train\")\n",
    "    os.makedirs(images_train_dir, exist_ok=True)\n",
    "    os.makedirs(labels_train_dir, exist_ok=True)\n",
    "\n",
    "    print(f\"Starting YOLO data preparation for single class '{object_class_name}'. Outputting to: {base_dataset_dir}\")\n",
    "\n",
    "    # For a single class, the class index is always 0\n",
    "    single_class_index = 0\n",
    "\n",
    "    for data_point in localization_data:\n",
    "        frame_num = data_point['frame_num']\n",
    "        frame_image_data = data_point['frame']\n",
    "        boxes_in_frame = data_point['boxes']\n",
    "\n",
    "        image_filename = f\"frame_{frame_num:05d}.jpg\"\n",
    "        label_filename = f\"frame_{frame_num:05d}.txt\"\n",
    "\n",
    "        image_path = os.path.join(images_train_dir, image_filename)\n",
    "        label_path = os.path.join(labels_train_dir, label_filename)\n",
    "\n",
    "        if isinstance(frame_image_data, np.ndarray):\n",
    "            cv2.imwrite(image_path, frame_image_data)\n",
    "        else:\n",
    "            print(f\"Warning: Frame data for frame_num {frame_num} is not a NumPy array. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        yolo_labels_for_this_frame = []\n",
    "        for box_info in boxes_in_frame:\n",
    "            x_norm_top_left = box_info['x']\n",
    "            y_norm_top_left = box_info['y']\n",
    "            w_norm = box_info['width']\n",
    "            h_norm = box_info['height']\n",
    "            # 'class_name' from box_info is ignored, we use single_class_index\n",
    "\n",
    "            x_center_norm = x_norm_top_left + (w_norm / 2)\n",
    "            y_center_norm = y_norm_top_left + (h_norm / 2)\n",
    "\n",
    "            yolo_labels_for_this_frame.append(\n",
    "                f\"{single_class_index} {x_center_norm:.6f} {y_center_norm:.6f} {w_norm:.6f} {h_norm:.6f}\"\n",
    "            )\n",
    "\n",
    "        with open(label_path, 'w') as f:\n",
    "            for line in yolo_labels_for_this_frame:\n",
    "                f.write(line + \"\\n\")\n",
    "\n",
    "    print(f\"Data preparation complete. Dataset at: {base_dataset_dir}\")\n",
    "    print(f\"Remember to create a data.yaml file in '{base_dataset_dir}' with:\")\n",
    "    print(\"train: images/train\")\n",
    "    print(\"val: images/val  # Or remove if no validation set\")\n",
    "    print(f\"nc: 1\")\n",
    "    print(f\"names: ['{object_class_name}']\")\n",
    "\n",
    "\n",
    "# --- Example of how you might structure your input and call the function ---\n",
    "# if __name__ == '__main__':\n",
    "#     dummy_frame_image_1 = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "#     cv2.putText(dummy_frame_image_1, \"Frame 1 Objects\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "#     dummy_frame_image_2 = np.zeros((720, 1280, 3), dtype=np.uint8)\n",
    "#     cv2.putText(dummy_frame_image_2, \"Frame 2 Objects\", (100, 100), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 0, 0), 3)\n",
    "\n",
    "#     # Note: 'class_name' in boxes is optional here, as it will be ignored by the function.\n",
    "#     # If your data source provides it, it's fine to include it.\n",
    "#     sample_localization_data_single_class = [\n",
    "#         {\n",
    "#             'frame_num': 101,\n",
    "#             'frame': dummy_frame_image_1,\n",
    "#             'boxes': [\n",
    "#                 {'x': 0.1, 'y': 0.2, 'width': 0.3, 'height': 0.25}, # No 'class_name' needed\n",
    "#                 {'x': 0.6, 'y': 0.5, 'width': 0.15, 'height': 0.20, 'class_name': 'irrelevant_name'} # 'class_name' will be ignored\n",
    "#             ]\n",
    "#         },\n",
    "#         {\n",
    "#             'frame_num': 102,\n",
    "#             'frame': dummy_frame_image_2,\n",
    "#             'boxes': [\n",
    "#                 {'x': 0.4, 'y': 0.3, 'width': 0.2, 'height': 0.2}\n",
    "#             ]\n",
    "#         }\n",
    "#     ]\n",
    "\n",
    "#     yolo_dataset_directory_single_class = \"./my_single_class_yolo_dataset\"\n",
    "#     custom_object_name = \"target_object\" # You can name your single class whatever you like\n",
    "\n",
    "#     prepare_yolo_data_single_class(\n",
    "#         sample_localization_data_single_class,\n",
    "#         yolo_dataset_directory_single_class,\n",
    "#         object_class_name=custom_object_name\n",
    "#     )\n",
    "\n",
    "    # After running, your data.yaml in './my_single_class_yolo_dataset/' should look like:\n",
    "    #\n",
    "    # train: images/train\n",
    "    # val: images/val # (if you create a validation set later)\n",
    "    #\n",
    "    # nc: 1\n",
    "    # names: ['target_object'] # Or whatever 'custom_object_name' you provided\n",
    "    #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_box(obj_list, frame_num, new_box):\n",
    "    for item in obj_list:\n",
    "        if item['frame_num'] == frame_num:\n",
    "            item['boxes'].append(new_box)\n",
    "            return\n",
    "    obj_list.append({'frame_num': frame_num, 'boxes': [new_box]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "[{'frame_num': 2181, 'boxes': [{'x': 0.23076923076923078, 'y': 0.44146341463414634, 'width': 0.047876602564102554, 'height': 0.08816621499548326}, {'x': 0.27197802197802196, 'y': 0.3463414634146342, 'width': 0.03427197802197804, 'height': 0.06847335140018065}]}, {'frame_num': 2297, 'boxes': [{'x': 0.42763157894736836, 'y': 0.4836448598130841, 'width': 0.023930921052631622, 'height': 0.06079958463136037}]}, {'frame_num': 2575, 'boxes': [{'x': 0.5741758241758242, 'y': 0.573170731707317, 'width': 0.046657509157509124, 'height': 0.07775519421860887}, {'x': 0.4107142857142857, 'y': 0.3902439024390244, 'width': 0.027306547619047626, 'height': 0.03383017163504965}]}, {'frame_num': 2906, 'boxes': [{'x': 0.5521978021978022, 'y': 0.46829268292682924, 'width': 0.08790636446886448, 'height': 0.051151761517615184}]}, {'frame_num': 2956, 'boxes': [{'x': 0.5013736263736264, 'y': 0.3024390243902439, 'width': 0.04393887362637366, 'height': 0.08737579042457091}]}, {'frame_num': 3922, 'boxes': [{'x': 0.44917582417582413, 'y': 0.5048780487804878, 'width': 0.11801167582417585, 'height': 0.24882565492321593}, {'x': 0.5865384615384616, 'y': 0.5195121951219512, 'width': 0.09210737179487177, 'height': 0.26104336043360427}]}, {'frame_num': 4091, 'boxes': [{'x': 0.364010989010989, 'y': 0.7048780487804878, 'width': 0.06046817765567768, 'height': 0.07845528455284555}, {'x': 0.6304945054945055, 'y': 0.7121951219512196, 'width': 0.03565132783882786, 'height': 0.08502710027100265}]}, {'frame_num': 4342, 'boxes': [{'x': 0.6002747252747253, 'y': 0.40731707317073174, 'width': 0.023162774725274695, 'height': 0.12694218608852753}, {'x': 0.2980769230769231, 'y': 0.5195121951219512, 'width': 0.07119391025641028, 'height': 0.06104336043360429}, {'x': 0.6881868131868132, 'y': 0.23902439024390248, 'width': 0.06181318681318686, 'height': 0.16560523938572716}]}, {'frame_num': 4499, 'boxes': [{'x': 0.24862637362637363, 'y': 0.22682926829268293, 'width': 0.053456959706959704, 'height': 0.1463188798554652}]}, {'frame_num': 6231, 'boxes': [{'x': 0.14697802197802198, 'y': 0.5878048780487806, 'width': 0.04104281135531134, 'height': 0.09275067750677503}]}, {'frame_num': 7501, 'boxes': [{'x': 0.5096153846153846, 'y': 0.6560975609756098, 'width': 0.03413461538461539, 'height': 0.08556910569105687}]}, {'frame_num': 8292, 'boxes': [{'x': 0.16346153846153846, 'y': 0.5341463414634147, 'width': 0.06049679487179486, 'height': 0.1241869918699187}]}, {'frame_num': 9585, 'boxes': [{'x': 0.6085164835164835, 'y': 0.6170731707317074, 'width': 0.05346268315018321, 'height': 0.153297199638663}, {'x': 0.6153846153846153, 'y': 0.8170731707317074, 'width': 0.05336538461538467, 'height': 0.10237127371273708}, {'x': 0.35989010989010983, 'y': 0.5975609756097561, 'width': 0.052089056776556814, 'height': 0.12188346883468834}]}, {'frame_num': 10462, 'boxes': [{'x': 0.5895020188425303, 'y': 0.49043062200956944, 'width': 0.06049798115746974, 'height': 0.05493974836080095}]}, {'frame_num': 19265, 'boxes': [{'x': 0.7250996015936254, 'y': 0.3679245283018868, 'width': 0.04521289840637455, 'height': 0.07744584206848357}]}, {'frame_num': 20188, 'boxes': [{'x': 0.06905710491367861, 'y': 0.29245283018867924, 'width': 0.045005395086321384, 'height': 0.11125087351502445}, {'x': 0.6905710491367861, 'y': 0.41037735849056606, 'width': 0.03963728419654717, 'height': 0.05443745632424876}]}, {'frame_num': 20726, 'boxes': [{'x': 0.2589641434262948, 'y': 0.25, 'width': 0.03739002324037184, 'height': 0.07777777777777778}]}, {'frame_num': 22325, 'boxes': [{'x': 0.36122177954847273, 'y': 0.36556603773584906, 'width': 0.058569887118193914, 'height': 0.07795248078266948}, {'x': 0.2602921646746348, 'y': 0.4080188679245283, 'width': 0.029291168658698533, 'height': 0.058647798742138366}]}, {'frame_num': 23930, 'boxes': [{'x': 0.28685258964143423, 'y': 0.7004716981132076, 'width': 0.06627241035856575, 'height': 0.12730607966457017}]}, {'frame_num': 24630, 'boxes': [{'x': 0.7397078353253652, 'y': 0.5660377358490566, 'width': 0.05039633134130147, 'height': 0.12933263452131377}]}, {'frame_num': 25666, 'boxes': [{'x': 0.6653386454183267, 'y': 0.294811320754717, 'width': 0.029453021248340032, 'height': 0.0588923829489867}]}, {'frame_num': 39300, 'boxes': [{'x': 0.5577689243027888, 'y': 0.5636792452830189, 'width': 0.09014774236387785, 'height': 0.20298742138364775}]}]\n"
     ]
    }
   ],
   "source": [
    "import tator\n",
    "MY_TOKEN = '0d3d74dc1595a2811b694478f714cd3e68f21354'\n",
    "api = tator.get_api(host='https://cloud.tator.io', token=MY_TOKEN)\n",
    "PROJECT_ID = 70\n",
    "# MEDIA_ID =    4291234\n",
    "MEDIA_ID = 4348803\n",
    "# MEDIA_ID = 4166376\n",
    "# MEDIA_ID = 4286688\n",
    "\n",
    "localizations = api.get_localization_list(PROJECT_ID, media_id=[MEDIA_ID])\n",
    "obj_dicts = []\n",
    "i = 0\n",
    "for localization in localizations:\n",
    "    # print(localization)\n",
    "    if localization.width is not None and localization.height is not None:\n",
    "        # if i < 10:\n",
    "        # if localization.width > 0 and localization.height > 0:\n",
    "            # print(localization)\n",
    "            add_box(obj_dicts, localization.frame, {'x': localization.x, \n",
    "                                                        'y': localization.y, \n",
    "                                                        'width': localization.width, \n",
    "                                                        'height': localization.height, \n",
    "                                                       }) \n",
    "\n",
    "   \n",
    "            # try:\n",
    "            #     img_path = api.get_localization_graphic(localization.id)\n",
    "            #     img_paths.append(img_path)\n",
    "            # except:\n",
    "            #     pass\n",
    "        # i += 1\n",
    "print(len(obj_dicts))\n",
    "print(obj_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "val = 0 \n",
    "for data in obj_dicts:\n",
    "    if len(data['boxes']) > 2:\n",
    "        val += 1\n",
    "print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading PS2222_20220601T175323Z_FWD_ROV01_HD.mp4...\n",
      "Download progress: 0%\n",
      "Download progress: 25.0%\n",
      "Download progress: 50.0%\n",
      "Download progress: 75.0%\n",
      "Download progress: 100.0%\n",
      "Download progress: 100%\n",
      "Download complete. Find at ./data/Images/PS2222_20220601T175323Z_FWD_ROV01_HD.mp4\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'k' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError downloading media \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMEDIA_ID\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# continue\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal successful downloads: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mk\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'k' is not defined"
     ]
    }
   ],
   "source": [
    "import tator\n",
    "MY_TOKEN = '0d3d74dc1595a2811b694478f714cd3e68f21354'\n",
    "api = tator.get_api(host='https://cloud.tator.io', token=MY_TOKEN)\n",
    "PROJECT_ID = 70\n",
    "MEDIA_ID =  4291234\n",
    "# MEDIA_ID = 9432747\n",
    "# MEDIA_IDS = 9431643 9431644\n",
    "# k = 0\n",
    "# for MEDIA_ID in range(9431643,9432434):\n",
    "try:\n",
    "    media = api.get_media(MEDIA_ID)\n",
    "    out_path = f\"./data/Images/{media.name}\"\n",
    "    print(f\"Downloading {media.name}...\")\n",
    "    for progress in tator.util.download_media(api, media, out_path):\n",
    "        print(f\"Download progress: {progress}%\")\n",
    "    print(f\"Download complete. Find at {out_path}\")\n",
    "    # k += 1\n",
    "except Exception as e:\n",
    "    print(f\"Error downloading media {MEDIA_ID}: {e}\")\n",
    "    # continue\n",
    "print(f\"Total successful downloads: {k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list count 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list count 1\n",
      "list count 2\n",
      "list count 3\n",
      "list count 4\n",
      "list count 5\n",
      "list count 6\n",
      "list count 7\n",
      "Error: Could not read frame 133696 from video /tmp/PS2208_20211005T141715Z_FWD_ROV01_HD.mp4.\n",
      "list count 8\n",
      "Error: Could not read frame 134551 from video /tmp/PS2208_20211005T141715Z_FWD_ROV01_HD.mp4.\n",
      "list count 9\n",
      "Error: Could not read frame 135326 from video /tmp/PS2208_20211005T141715Z_FWD_ROV01_HD.mp4.\n",
      "list count 10\n",
      "list count 11\n",
      "list count 12\n",
      "list count 13\n",
      "list count 14\n",
      "list count 15\n",
      "list count 16\n",
      "list count 17\n",
      "list count 18\n",
      "list count 19\n",
      "list count 20\n",
      "list count 21\n",
      "list count 22\n",
      "list count 23\n",
      "list count 24\n",
      "list count 25\n",
      "list count 26\n",
      "list count 27\n",
      "list count 28\n",
      "list count 29\n",
      "list count 30\n",
      "list count 31\n",
      "list count 32\n",
      "list count 33\n",
      "list count 34\n",
      "list count 35\n",
      "list count 36\n",
      "list count 37\n",
      "list count 38\n",
      "list count 39\n",
      "list count 40\n",
      "list count 41\n",
      "list count 42\n",
      "list count 43\n",
      "list count 44\n",
      "list count 45\n",
      "list count 46\n",
      "list count 47\n",
      "list count 48\n",
      "list count 49\n",
      "list count 50\n",
      "list count 51\n",
      "list count 52\n",
      "list count 53\n",
      "list count 54\n",
      "list count 55\n",
      "Error: Could not read frame 133760 from video /tmp/PS2208_20211005T141715Z_FWD_ROV01_HD.mp4.\n",
      "list count 56\n",
      "Error: Could not read frame 133688 from video /tmp/PS2208_20211005T141715Z_FWD_ROV01_HD.mp4.\n",
      "list count 57\n",
      "Error: Could not read frame 133840 from video /tmp/PS2208_20211005T141715Z_FWD_ROV01_HD.mp4.\n",
      "list count 58\n",
      "Error: Could not read frame 133943 from video /tmp/PS2208_20211005T141715Z_FWD_ROV01_HD.mp4.\n",
      "list count 59\n",
      "Error: Could not read frame 133998 from video /tmp/PS2208_20211005T141715Z_FWD_ROV01_HD.mp4.\n",
      "list count 60\n",
      "Error: Could not read frame 134021 from video /tmp/PS2208_20211005T141715Z_FWD_ROV01_HD.mp4.\n",
      "list count 61\n",
      "list count 62\n",
      "list count 63\n",
      "list count 64\n",
      "Error: Could not read frame 134037 from video /tmp/PS2208_20211005T141715Z_FWD_ROV01_HD.mp4.\n",
      "list count 65\n",
      "Error: Could not read frame 134133 from video /tmp/PS2208_20211005T141715Z_FWD_ROV01_HD.mp4.\n",
      "list count 66\n",
      "Error: Could not read frame 134178 from video /tmp/PS2208_20211005T141715Z_FWD_ROV01_HD.mp4.\n",
      "list count 67\n",
      "Error: Could not read frame 134213 from video /tmp/PS2208_20211005T141715Z_FWD_ROV01_HD.mp4.\n",
      "list count 68\n",
      "Error: Could not read frame 134324 from video /tmp/PS2208_20211005T141715Z_FWD_ROV01_HD.mp4.\n",
      "list count 69\n",
      "Error: Could not read frame 134383 from video /tmp/PS2208_20211005T141715Z_FWD_ROV01_HD.mp4.\n",
      "list count 70\n",
      "Error: Could not read frame 134394 from video /tmp/PS2208_20211005T141715Z_FWD_ROV01_HD.mp4.\n",
      "list count 71\n",
      "Error: Could not read frame 134485 from video /tmp/PS2208_20211005T141715Z_FWD_ROV01_HD.mp4.\n",
      "list count 72\n",
      "Error: Could not read frame 134504 from video /tmp/PS2208_20211005T141715Z_FWD_ROV01_HD.mp4.\n",
      "list count 73\n",
      "Error: Could not read frame 134516 from video /tmp/PS2208_20211005T141715Z_FWD_ROV01_HD.mp4.\n",
      "list count 74\n",
      "Error: Could not read frame 134571 from video /tmp/PS2208_20211005T141715Z_FWD_ROV01_HD.mp4.\n",
      "list count 75\n",
      "Error: Could not read frame 134578 from video /tmp/PS2208_20211005T141715Z_FWD_ROV01_HD.mp4.\n",
      "list count 76\n",
      "Error: Could not read frame 134610 from video /tmp/PS2208_20211005T141715Z_FWD_ROV01_HD.mp4.\n",
      "list count 77\n",
      "Error: Could not read frame 134641 from video /tmp/PS2208_20211005T141715Z_FWD_ROV01_HD.mp4.\n",
      "list count 78\n",
      "Error: Could not read frame 134693 from video /tmp/PS2208_20211005T141715Z_FWD_ROV01_HD.mp4.\n",
      "list count 79\n",
      "Error: Could not read frame 134735 from video /tmp/PS2208_20211005T141715Z_FWD_ROV01_HD.mp4.\n",
      "list count 80\n",
      "Error: Could not read frame 134811 from video /tmp/PS2208_20211005T141715Z_FWD_ROV01_HD.mp4.\n",
      "list count 81\n",
      "Error: Could not read frame 134819 from video /tmp/PS2208_20211005T141715Z_FWD_ROV01_HD.mp4.\n",
      "list count 82\n",
      "Error: Could not read frame 134826 from video /tmp/PS2208_20211005T141715Z_FWD_ROV01_HD.mp4.\n",
      "list count 83\n",
      "Error: Could not read frame 134840 from video /tmp/PS2208_20211005T141715Z_FWD_ROV01_HD.mp4.\n",
      "list count 84\n",
      "Error: Could not read frame 134851 from video /tmp/PS2208_20211005T141715Z_FWD_ROV01_HD.mp4.\n",
      "list count 85\n",
      "Error: Could not read frame 134896 from video /tmp/PS2208_20211005T141715Z_FWD_ROV01_HD.mp4.\n",
      "list count 86\n",
      "Error: Could not read frame 134942 from video /tmp/PS2208_20211005T141715Z_FWD_ROV01_HD.mp4.\n",
      "list count 87\n",
      "Error: Could not read frame 134974 from video /tmp/PS2208_20211005T141715Z_FWD_ROV01_HD.mp4.\n",
      "list count 88\n",
      "Error: Could not read frame 134960 from video /tmp/PS2208_20211005T141715Z_FWD_ROV01_HD.mp4.\n",
      "list count 89\n",
      "Error: Could not read frame 135038 from video /tmp/PS2208_20211005T141715Z_FWD_ROV01_HD.mp4.\n",
      "list count 90\n",
      "Error: Could not read frame 135036 from video /tmp/PS2208_20211005T141715Z_FWD_ROV01_HD.mp4.\n",
      "list count 91\n",
      "Error: Could not read frame 135085 from video /tmp/PS2208_20211005T141715Z_FWD_ROV01_HD.mp4.\n",
      "list count 92\n",
      "Error: Could not read frame 135117 from video /tmp/PS2208_20211005T141715Z_FWD_ROV01_HD.mp4.\n",
      "list count 93\n",
      "Error: Could not read frame 135128 from video /tmp/PS2208_20211005T141715Z_FWD_ROV01_HD.mp4.\n",
      "list count 94\n",
      "Error: Could not read frame 135160 from video /tmp/PS2208_20211005T141715Z_FWD_ROV01_HD.mp4.\n",
      "list count 95\n",
      "Error: Could not read frame 135190 from video /tmp/PS2208_20211005T141715Z_FWD_ROV01_HD.mp4.\n",
      "list count 96\n",
      "Error: Could not read frame 135224 from video /tmp/PS2208_20211005T141715Z_FWD_ROV01_HD.mp4.\n",
      "list count 97\n",
      "list count 98\n",
      "list count 99\n",
      "list count 100\n",
      "list count 101\n",
      "list count 102\n",
      "list count 103\n",
      "list count 104\n",
      "list count 105\n",
      "list count 106\n",
      "list count 107\n",
      "list count 108\n",
      "list count 109\n",
      "list count 110\n",
      "list count 111\n",
      "list count 112\n",
      "list count 113\n",
      "list count 114\n",
      "list count 115\n",
      "list count 116\n",
      "list count 117\n",
      "list count 118\n",
      "list count 119\n",
      "list count 120\n",
      "list count 121\n",
      "list count 122\n",
      "list count 123\n",
      "list count 124\n",
      "list count 125\n",
      "list count 126\n",
      "list count 127\n",
      "list count 128\n",
      "list count 129\n",
      "list count 130\n",
      "list count 131\n",
      "list count 132\n",
      "list count 133\n",
      "list count 134\n",
      "list count 135\n",
      "list count 136\n",
      "list count 137\n",
      "list count 138\n",
      "list count 139\n",
      "list count 140\n",
      "list count 141\n",
      "list count 142\n",
      "list count 143\n",
      "list count 144\n",
      "list count 145\n",
      "list count 146\n",
      "list count 147\n",
      "list count 148\n",
      "list count 149\n",
      "list count 150\n",
      "list count 151\n",
      "list count 152\n",
      "list count 153\n",
      "list count 154\n",
      "list count 155\n",
      "list count 156\n",
      "list count 157\n",
      "list count 158\n",
      "list count 159\n",
      "list count 160\n",
      "list count 161\n",
      "list count 162\n",
      "list count 163\n",
      "list count 164\n",
      "list count 165\n",
      "list count 166\n",
      "list count 167\n",
      "list count 168\n",
      "list count 169\n",
      "list count 170\n",
      "list count 171\n",
      "list count 172\n",
      "list count 173\n",
      "list count 174\n",
      "list count 175\n",
      "list count 176\n",
      "list count 177\n",
      "list count 178\n",
      "list count 179\n",
      "list count 180\n",
      "list count 181\n",
      "list count 182\n",
      "list count 183\n",
      "list count 184\n",
      "list count 185\n",
      "list count 186\n",
      "list count 187\n",
      "list count 188\n",
      "list count 189\n",
      "list count 190\n",
      "list count 191\n",
      "list count 192\n",
      "list count 193\n",
      "list count 194\n",
      "list count 195\n",
      "list count 196\n",
      "list count 197\n",
      "list count 198\n",
      "list count 199\n",
      "list count 200\n",
      "list count 201\n",
      "list count 202\n",
      "list count 203\n",
      "list count 204\n",
      "list count 205\n",
      "list count 206\n",
      "list count 207\n",
      "list count 208\n",
      "list count 209\n",
      "list count 210\n",
      "list count 211\n",
      "list count 212\n",
      "list count 213\n",
      "list count 214\n",
      "list count 215\n",
      "list count 216\n",
      "list count 217\n",
      "list count 218\n",
      "list count 219\n",
      "list count 220\n",
      "list count 221\n",
      "list count 222\n",
      "list count 223\n",
      "list count 224\n",
      "list count 225\n",
      "list count 226\n",
      "list count 227\n",
      "list count 228\n",
      "list count 229\n",
      "list count 230\n",
      "list count 231\n",
      "list count 232\n",
      "list count 233\n",
      "list count 234\n",
      "list count 235\n",
      "list count 236\n",
      "list count 237\n",
      "list count 238\n",
      "list count 239\n",
      "list count 240\n",
      "list count 241\n",
      "list count 242\n",
      "list count 243\n",
      "list count 244\n",
      "list count 245\n",
      "list count 246\n",
      "list count 247\n",
      "list count 248\n",
      "list count 249\n",
      "list count 250\n",
      "list count 251\n",
      "list count 252\n",
      "list count 253\n",
      "list count 254\n",
      "list count 255\n",
      "list count 256\n",
      "list count 257\n",
      "list count 258\n",
      "list count 259\n",
      "list count 260\n",
      "list count 261\n",
      "list count 262\n",
      "list count 263\n",
      "list count 264\n",
      "list count 265\n",
      "list count 266\n",
      "list count 267\n",
      "list count 268\n",
      "list count 269\n",
      "list count 270\n",
      "list count 271\n",
      "list count 272\n",
      "list count 273\n",
      "list count 274\n",
      "list count 275\n",
      "list count 276\n",
      "list count 277\n",
      "list count 278\n",
      "list count 279\n",
      "list count 280\n",
      "list count 281\n",
      "list count 282\n",
      "list count 283\n",
      "list count 284\n",
      "list count 285\n",
      "list count 286\n",
      "list count 287\n",
      "list count 288\n",
      "list count 289\n",
      "list count 290\n",
      "list count 291\n",
      "list count 292\n",
      "list count 293\n",
      "list count 294\n",
      "list count 295\n",
      "list count 296\n",
      "list count 297\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for frame in obj_dicts:\n",
    "    print(f'list count {i}')\n",
    "    try:\n",
    "        frame['frame'] = get_frame_from_video(out_path, frame['frame_num'])\n",
    "    except:\n",
    "        print('failed')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_yolo_data_single_class(obj_dicts, './data', object_class_name=\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "def finetune_yolo_model(data_yaml_path, pretrained_model_name='yolov8n.pt', epochs=50, batch_size=16, img_size=640, project_name='yolo_finetune', run_name='exp'):\n",
    "    \"\"\"\n",
    "    Fine-tunes a YOLO model on a custom dataset.\n",
    "\n",
    "    Args:\n",
    "        data_yaml_path (str): Path to your data.yaml file.\n",
    "        pretrained_model_name (str): Name of the pretrained model to start from (e.g., 'yolov8n.pt', 'yolov8s.pt').\n",
    "        epochs (int): Number of training epochs.\n",
    "        batch_size (int): Batch size for training.\n",
    "        img_size (int): Input image size for the model.\n",
    "        project_name (str): Name of the project directory where results will be saved.\n",
    "        run_name (str): Name of the specific run/experiment.\n",
    "    \"\"\"\n",
    "    # Load a pretrained YOLO model\n",
    "    model = YOLO(pretrained_model_name)\n",
    "\n",
    "    print(f\"Starting fine-tuning with model: {pretrained_model_name}\")\n",
    "    print(f\"Dataset configuration: {data_yaml_path}\")\n",
    "    print(f\"Training for {epochs} epochs with batch size {batch_size} and image size {img_size}.\")\n",
    "\n",
    "    # Train the model\n",
    "    results = model.train(\n",
    "        data=data_yaml_path,\n",
    "        epochs=epochs,\n",
    "        batch=batch_size,\n",
    "        imgsz=img_size,\n",
    "        project=project_name, # Results will be saved in 'runs/detect/project_name/run_name'\n",
    "        name=run_name,\n",
    "        # device=0,  # Uncomment to specify GPU, e.g., 0 for the first GPU\n",
    "        # workers=8, # Number of dataloader workers\n",
    "        # patience=10, # Early stopping patience\n",
    "        # exist_ok=True # if you want to overwrite existing run with the same name\n",
    "    )\n",
    "\n",
    "    print(\"Fine-tuning complete.\")\n",
    "    print(f\"Results saved to: {results.save_dir}\") # Ultralytics 8.0.x returns a Results object\n",
    "    # For older versions, the path might be under model.trainer.save_dir or similar.\n",
    "    # The best model weights are typically saved as 'best.pt' in the run directory.\n",
    "\n",
    "\n",
    "dataset_yaml_file = \"/path/to/your_dataset/data.yaml\"\n",
    "\n",
    "# Check if the YAML file exists\n",
    "if not os.path.exists(dataset_yaml_file):\n",
    "    print(f\"Error: Dataset YAML file not found at {dataset_yaml_file}\")\n",
    "    print(\"Please create the data.yaml file and ensure paths are correct.\")\n",
    "else:\n",
    "    finetune_yolo_model(\n",
    "        data_yaml_path=dataset_yaml_file,\n",
    "        pretrained_model_name='yolov8s.pt', # Start with a small model like yolov8n.pt or yolov8s.pt\n",
    "        epochs=25, # Start with fewer epochs to test\n",
    "        batch_size=8, # Adjust based on your GPU memory\n",
    "        img_size=640,\n",
    "        project_name='custom_object_detection',\n",
    "        run_name='first_finetune_run'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
